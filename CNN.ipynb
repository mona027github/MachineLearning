{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916aa2c5-b068-44b2-b228-9ac67a51751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F5521EABA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F552270410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F552270690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F552270910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F552270B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0971b-aa5e-4f0a-a685-3d298df9646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, Dense,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbb238-4f5b-41cf-af59-dddc67b6bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "            Conv2D(32,kernal_size =(3,3),activation='relu',input_shape= (28,28,1)),\n",
    "            MaxPooling(pool_size =(2,2),\n",
    "            Dropout(0.25),\n",
    "            Flatten(),\n",
    "            Dense(128,activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(10,activation ='softmax')\n",
    "            ])\n",
    "\n",
    "model.compile(optimizer ='adam',\n",
    "              loss ='categorical_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data =(x_test, y_test),\n",
    "          epochs =10,\n",
    "          batch_size = 128)\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test)\n",
    "print(loss,accuracy)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e60a11-3403-48e7-aa93-453b6a354ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Sequential CNN on MNIST — step-by-step demo (TensorFlow / Keras)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Save this as mnist_cnn_demo.py or run in a notebook cell\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Sequential CNN on MNIST — step-by-step demo (TensorFlow / Keras)\n",
    "# Save this as mnist_cnn_demo.py or run in a notebook cell\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 0) Reproducibility (helps but not perfect across hardware)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1) Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"Shapes (train_images, train_labels, test_images, test_labels):\",\n",
    "      x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# 2) Preprocess: reshape, normalize, one-hot encode\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test  = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat  = to_categorical(y_test, 10)\n",
    "\n",
    "# 3) Build a Sequential CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 4) Compile: optimizer, loss, metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5) Model summary (structural check)\n",
    "model.summary()\n",
    "\n",
    "# 6) Train\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "history = model.fit(x_train, y_train_cat,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=2)\n",
    "\n",
    "# 7) Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}  |  Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# 8) Plot training curves (accuracy and loss)\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/mnist_training_plot.png') \n",
    "plt.show()\n",
    "\n",
    "# 9) Save model and an example predictions grid\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model.save('outputs/mnist_cnn.h5')\n",
    "plt.savefig('outputs/mnist_training_plot.png')  # optional: you may call plt.savefig earlier\n",
    "\n",
    "# 10) Show some predictions\n",
    "preds = model.predict(x_test[:12])\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "import matplotlib.pyplot as mpl\n",
    "fig, axes = mpl.subplots(3,4, figsize=(8,6))\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
    "    ax.set_title(f\"Pred: {pred_labels[i]} | True: {y_test[i]}\")\n",
    "    ax.axis('off')\n",
    "mpl.tight_layout()\n",
    "mpl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519d814-a14a-4768-8bdb-a2dcc540cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train\n",
    "x_train.shape[1]\n",
    "print(x_train.shape)  # Output: (60000, 28, 28)\n",
    " \n",
    "# Reshape to flatten images\n",
    "x_train = x_train.reshape(-1, 28*28)   # Output: (60000,784)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Reshape and normalize\n",
    "x_train= x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "\n",
    "# Next One-hot encode labels using to_categorical\n",
    "y_train = to_categorical(y_train,10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer 1 + Max Pooling\n",
    "model.add(Conv2D(32,(3,3), activation ='relu', input_shape(32,3,3)))\n",
    "model.add(MaxPooling2D(pool_size =(2,2))\n",
    "          \n",
    "# Convolutional Layer 2 + Max Pooling\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu')\n",
    "model.add(MaxPooling2D(pool_size = (2,2))\n",
    "\n",
    "# Flatten the feature map\n",
    "model.add(Flatten())\n",
    "          \n",
    "# Fully Connected Layers\n",
    "model.add(Dense(128,activation='relu'))\n",
    "    \n",
    "# Output layer with softmax for classification\n",
    "model.add(Dense(10,activation ='softmax'))\n",
    "          \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361a09f-bf46-4704-bc1d-504b57d01f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch minimal CNN on MNIST\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_ds = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.MNIST(\".\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*5*5,128), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "opt = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train for 5 epochs (loop omitted for brevity) — use typical training loop (forward, loss, backward, step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
